{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "9e79b3d7-9970-4ad1-be53-d160f5a57e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "import pandas\n",
    "import torch\n",
    "import numpy\n",
    "from src import tokenize\n",
    "from src import utils\n",
    "from CustomDatasets import SimpleDataset\n",
    "from Models import SimpleModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "9f1ac552-8f21-4bdc-aa2e-0349bb587050",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elabo\\Documents\\GitHub\\RetentionTimeEstimators\\src\\tokenize.py:23: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  sequence = str(row[0])\n",
      "C:\\Users\\elabo\\Documents\\GitHub\\RetentionTimeEstimators\\src\\tokenize.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  preTokens.append((sequence, row[1]))\n",
      "C:\\Users\\elabo\\Documents\\GitHub\\RetentionTimeEstimators\\src\\tokenize.py:29: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  preTokens.append((removedColon, row[1]))\n"
     ]
    }
   ],
   "source": [
    "vocab = tokenize.readVocabulary(\"vocab.csv\")\n",
    "data = tokenize.readData(\"CalibratorTestingMultipleFiles.csv\")\n",
    "preTokens = tokenize.getPreTokens(data)\n",
    "tokens = tokenize.tokenizePreTokens(preTokens, vocab, 100, tokenize.TokenFormat.TwoDimensional)\n",
    "train, test = utils.splitData(tokens, 0.9, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "fc0ef44b-364a-4a6c-a401-59d8edaee988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[18, 20,  8,  4,  3, 16, 10,  6,  4, 15,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0]]),\n",
       " 0.2616880507452073)"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0][0], train[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "574a34ce-2177-4f03-8acc-05950ebcd82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('training data: 263930', ' | testing data: 29326', ' | total: 293256')"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"training data: \"+str(len(train)), \" | testing data: \"+str(len(test)), \" | total: \"+str(len(train)+len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "655c58be-37d3-41aa-af65-5ae057301f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSequences = []\n",
    "trainingRetentionTimes = []\n",
    "for i in train:\n",
    "    trainingSequences.append(i[0])\n",
    "    trainingRetentionTimes.append(i[1])\n",
    "\n",
    "testingSequences = []\n",
    "testingRetentionTimes = []\n",
    "for i in train:\n",
    "    testingSequences.append(i[0])\n",
    "    testingRetentionTimes.append(i[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "a32306cf-61b6-4e2b-a7c3-1521cedbce05",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSequences = numpy.stack(trainingSequences)\n",
    "trainingRetentionTimes = numpy.stack(trainingRetentionTimes)\n",
    "testingSequences = numpy.stack(testingSequences)\n",
    "testingRetentionTimes = numpy.stack(testingRetentionTimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "f77f1171-88af-4cd2-a558-421a3367cd86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((263930, 2, 100), (263930,), (263930, 2, 100), (263930,))"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingSequences.shape, trainingRetentionTimes.shape, testingSequences.shape, testingRetentionTimes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "d8b68b0f-748d-4331-b906-4c1ee9b5d688",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingDataset = SimpleDataset.PeptidesWithRetentionTimes(trainingSequences, trainingRetentionTimes)\n",
    "testingDataset = SimpleDataset.PeptidesWithRetentionTimes(testingSequences, testingRetentionTimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "579bab7a-594f-40ce-95fd-bbd83091f300",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingDataloader = torch.utils.data.DataLoader(trainingDataset, batch_size=32, shuffle=True, drop_last=True)\n",
    "testingDataloader = torch.utils.data.DataLoader(testingDataset, batch_size=32, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "213b721c-df2f-4de0-94ba-60a31fd59620",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleModel.AttentionRegression(2707, 1024, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca170a82-3860-4dbd-96a0-3fd0736bc882",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
